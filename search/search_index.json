{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HEAL Data Utilities \u00b6 The HEAL data utilities python package provides data packaging tools for the HEAL data ecosystem to facilitate data discovery,sharing, and harmonization with a focus on the HEAL platform data consultancy (DSC). Currently, the focus of the repo is on generating data-dictionaries (see Variable level metadata section below). However, in the future, this will be expanded for all heal specific data packaging functions (e.g., study and file level metadata and data). Installation \u00b6 To install the latest official release of healdata-utils, from your computer's command prompt, run: pip install healdata-utils --pre ( NOTE: currently in pre-lease ) pip install git+https://github.com/norc-heal/healdata-utils.git Variable level metadata (data dictionaries) \u00b6 The healdata-utils variable level metadata (vlmd) tool inputs a variety of different input file types and exports HEAL-formatted data dictionaries (JSON and CSV formats). Additionally, exported validation (ie \"error\") reports provide the user information as to a. if the exported data dictionary is valid according to HEAL specifications (see the schema repository here ). For support formats and more detailed software specific instructions and recommendations, see here Basic usage \u00b6 The vlmd tool can be used via python or the command line. Using from python \u00b6 From your current working directory in python, run: from healdata_utils.cli import convert_to_vlmd # description and title are optional. If submitting through platform, can fill these out there. description = \"This is a proof of concept to demonstrate the healdata-utils functionality\" title = \"Healdata-utils Demonstration Data Dictionary\" healdir = \"output\" # can also specify a file name if desired (eg output/thisismynewdd.csv) inputpath = \"input/my-redcap-data-dictionary-export.csv\" data_dictionaries = convert_to_vlmd ( filepath = inputpath , outputdir = healdir , inputtype = input_type , #if not specified, looks for suffix data_dictionary_props = { \"title\" : title , \"description\" : description } #data_dictionary_props is optional ) This will output the data dictionaries to the specified output directory (see ooutput section below) and also save the json/csv versions in the data_dictionaries object. For the available input file formats (ie the available choices for the inputtype parameter), one can run (from python): from healdata_utils.cli import input_descriptions input_descriptions The input_descriptions object contains the choice for inputtype as the key and the description as the value. Using from the command line \u00b6 From your current working directory run: (note the \\ at the end of each line signals a line continuation for ease in understanding the long one line command.) Again the --title and --description options are optional. For descriptions on the different flags/options, run vlmd --help vlmd --filepath \"data/example_pyreadstat_output.sav\" \\ --outputdir \"output-cli\" \\ --title \"Healdata-utils Demonstration Data Dictionary\" \\ --description \"This is a proof of concept to demonstrate the healdata-utils functionality\" Output \u00b6 Both the python and command line routes will result in a JSON and CSV version of the HEAL data dictionary in the output folder along with the validation reports in the errors folder. See below: input/input/my-redcap-data-dictionary-export.csv : your input file output/errors/heal-csv-errors.json : outputted validation report for table in csv file against frictionless schema see schema here output/errors/heal-json-errors.json : outputted jsonschema validation report. see schema here Important The main difference* between the CSV and JSON data dictionary validation lies in the way the data dictionaries are structured and the additional metadata included in the JSON data dictionary. The CSV data dictionary is a plain tabular representation with no additional metadata, while the JSON dataset includes fields along with additional metadata in the form of a root description and title. for field-specific differences, see the schemas in the documentation. output/heal-csvtemplate-data-dictionary.csv : This is the CSV data dictionary output/heal-jsontemplate-data-dictionary.json : This is the JSON version of the data dictionary Note, only the JSON version will have the user-specified title and description Interactive notebooks \u00b6 See the below notebooks demonstrating use and workflows using the convert_to_vlmd in python and vlmd in the command line. Clicking on the \"binder badges\" will bring you to an interactive notebook page where you can test out the notebooks. Here, healdata-utils comes pre-installed. Generating a heal data dictionary from a variety of input files click here for static notebook click binder badge for interactive [in development] Creating and iterating over a csv data dictionary to create a valid data dictionary file click here","title":"Home"},{"location":"#heal-data-utilities","text":"The HEAL data utilities python package provides data packaging tools for the HEAL data ecosystem to facilitate data discovery,sharing, and harmonization with a focus on the HEAL platform data consultancy (DSC). Currently, the focus of the repo is on generating data-dictionaries (see Variable level metadata section below). However, in the future, this will be expanded for all heal specific data packaging functions (e.g., study and file level metadata and data).","title":"HEAL Data Utilities"},{"location":"#installation","text":"To install the latest official release of healdata-utils, from your computer's command prompt, run: pip install healdata-utils --pre ( NOTE: currently in pre-lease ) pip install git+https://github.com/norc-heal/healdata-utils.git","title":"Installation"},{"location":"#variable-level-metadata-data-dictionaries","text":"The healdata-utils variable level metadata (vlmd) tool inputs a variety of different input file types and exports HEAL-formatted data dictionaries (JSON and CSV formats). Additionally, exported validation (ie \"error\") reports provide the user information as to a. if the exported data dictionary is valid according to HEAL specifications (see the schema repository here ). For support formats and more detailed software specific instructions and recommendations, see here","title":"Variable level metadata (data dictionaries)"},{"location":"#basic-usage","text":"The vlmd tool can be used via python or the command line.","title":"Basic usage"},{"location":"#using-from-python","text":"From your current working directory in python, run: from healdata_utils.cli import convert_to_vlmd # description and title are optional. If submitting through platform, can fill these out there. description = \"This is a proof of concept to demonstrate the healdata-utils functionality\" title = \"Healdata-utils Demonstration Data Dictionary\" healdir = \"output\" # can also specify a file name if desired (eg output/thisismynewdd.csv) inputpath = \"input/my-redcap-data-dictionary-export.csv\" data_dictionaries = convert_to_vlmd ( filepath = inputpath , outputdir = healdir , inputtype = input_type , #if not specified, looks for suffix data_dictionary_props = { \"title\" : title , \"description\" : description } #data_dictionary_props is optional ) This will output the data dictionaries to the specified output directory (see ooutput section below) and also save the json/csv versions in the data_dictionaries object. For the available input file formats (ie the available choices for the inputtype parameter), one can run (from python): from healdata_utils.cli import input_descriptions input_descriptions The input_descriptions object contains the choice for inputtype as the key and the description as the value.","title":"Using from python"},{"location":"#using-from-the-command-line","text":"From your current working directory run: (note the \\ at the end of each line signals a line continuation for ease in understanding the long one line command.) Again the --title and --description options are optional. For descriptions on the different flags/options, run vlmd --help vlmd --filepath \"data/example_pyreadstat_output.sav\" \\ --outputdir \"output-cli\" \\ --title \"Healdata-utils Demonstration Data Dictionary\" \\ --description \"This is a proof of concept to demonstrate the healdata-utils functionality\"","title":"Using from the command line"},{"location":"#output","text":"Both the python and command line routes will result in a JSON and CSV version of the HEAL data dictionary in the output folder along with the validation reports in the errors folder. See below: input/input/my-redcap-data-dictionary-export.csv : your input file output/errors/heal-csv-errors.json : outputted validation report for table in csv file against frictionless schema see schema here output/errors/heal-json-errors.json : outputted jsonschema validation report. see schema here Important The main difference* between the CSV and JSON data dictionary validation lies in the way the data dictionaries are structured and the additional metadata included in the JSON data dictionary. The CSV data dictionary is a plain tabular representation with no additional metadata, while the JSON dataset includes fields along with additional metadata in the form of a root description and title. for field-specific differences, see the schemas in the documentation. output/heal-csvtemplate-data-dictionary.csv : This is the CSV data dictionary output/heal-jsontemplate-data-dictionary.json : This is the JSON version of the data dictionary Note, only the JSON version will have the user-specified title and description","title":"Output"},{"location":"#interactive-notebooks","text":"See the below notebooks demonstrating use and workflows using the convert_to_vlmd in python and vlmd in the command line. Clicking on the \"binder badges\" will bring you to an interactive notebook page where you can test out the notebooks. Here, healdata-utils comes pre-installed. Generating a heal data dictionary from a variety of input files click here for static notebook click binder badge for interactive [in development] Creating and iterating over a csv data dictionary to create a valid data dictionary file click here","title":"Interactive notebooks"},{"location":"contributing/","text":"","title":"Contributing"},{"location":"install/","text":"","title":"Install"},{"location":"vlmd/","text":"Variable level metadata (data dictionaries) \u00b6 The healdata-utils variable level metadata (vlmd) tool inputs a variety of different input file types and exports HEAL-formatted data dictionaries (JSON and CSV formats). Additionally, exported validation (ie \"error\") reports provide the user information as to a. if the exported data dictionary is valid according to HEAL specifications and information on how to modify one's data dictionary to conform to make HEAL compliant. For support formats and more detailed software-specific instructions and recommendations, see here For more information on variable level metadata properties (fields), see the csv field specification and json field specification . Typical workflows for creating a HEAL-compliant data dictionary include: Run the vlmd command (or convert_to_vlmd if in python) to generate a HEAL-compliant data dictionary via your desired input format (See the basic usage section on the homepage for general installation and usage information.) Add/annotate with additional information in your preferred HEAL data dictionary format (either json or csv ). To further annotate and use the data dictionary, see the variable level metadata field property information below: csv data dictionary json data dictionary Run the vlmd command again with your HEAL data dictioanry as input to validate. Repeat 2 and 3 until you are ready to submit. Remember, currently only name and description are required.","title":"Index"},{"location":"vlmd/#variable-level-metadata-data-dictionaries","text":"The healdata-utils variable level metadata (vlmd) tool inputs a variety of different input file types and exports HEAL-formatted data dictionaries (JSON and CSV formats). Additionally, exported validation (ie \"error\") reports provide the user information as to a. if the exported data dictionary is valid according to HEAL specifications and information on how to modify one's data dictionary to conform to make HEAL compliant. For support formats and more detailed software-specific instructions and recommendations, see here For more information on variable level metadata properties (fields), see the csv field specification and json field specification . Typical workflows for creating a HEAL-compliant data dictionary include: Run the vlmd command (or convert_to_vlmd if in python) to generate a HEAL-compliant data dictionary via your desired input format (See the basic usage section on the homepage for general installation and usage information.) Add/annotate with additional information in your preferred HEAL data dictionary format (either json or csv ). To further annotate and use the data dictionary, see the variable level metadata field property information below: csv data dictionary json data dictionary Run the vlmd command again with your HEAL data dictioanry as input to validate. Repeat 2 and 3 until you are ready to submit. Remember, currently only name and description are required.","title":"Variable level metadata (data dictionaries)"},{"location":"vlmd/supported_input_formats/","text":"Supported Input Formats \u00b6 In this section, supported formats for generating heal-compliant data dictionaries are listed. We also provide additional instructions on how to get the necessary input files format/software. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for either the csv data dictionary click here and for the json data dictionary click here csv Datasets \u00b6 CSV (comma-separated values) is the main open tabular data format for storage and exchange. It is easy to create and understand using basic text editors in addition to popular spreadsheet software like Google Sheets and Excel. Importantly, it is simple and can be easily integrated into web applications and just about any software. Currently, the HEAL data utilities vlmd function can infer a minimal-HEAL compliant dataset by inferring name , type ,and enum (i.e., possible values). After this minimal data dictionary is generated, the researcher can further annotate it with fields' description and other optional properties in either the HEAL-compliant csv or json data dictionary (see the HEAL data dictionary template sections below for more information) csv HEAL data dictionary (e.g., from template) \u00b6 HEAL data utilities can also input a csv HEAL data dictionary either from a manually filled out template or as an additional step after additional annotation (e.g., from the HEAL csv data dictionary output of the above file formats). Creating a csv HEAL data dictionary \u00b6 Use the template and start from scratch Click here to download a blank csv HEAL data dictionary template here Click here to download an example of filled out csv HEAL data dictionary template here Output from one of the below software-specific formats and then further annotate. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for either the csv data dictionary click here Validate with the vlmd command \u00b6 After finishing your work on the csv HEAL data dictionary, run the vlmd command to ensure it is HEAL-compliant with: vlmd --filepath data/heal-dd-output.csv --inputtype csvtemplate json HEAL data dictionary (e.g., from template) \u00b6 While the csv HEAL data dictionary provides a tabular format for HEAL-compliant data dictionaries, ultimately, these csv data dictionary files are converted to a json file (the most common format to store and exchange data within web applications such as the HEAL data platform). The HEAL data utilities vlmd tool can also input this json HEAL data dictionary either from a manually filled out template or as an additional step after additional annotation. Another advantage of json HEAL data dictionaries is that one can specify metadata describing the data dictionary as a whole (e.g., the description and title ). Creating a json HEAL data dictionary \u00b6 Use the template and start from scratch (click on the template below to expand) Click here to download a blank json HEAL data dictionary template here Click here to download an example of filled out json HEAL data dictionary template here Output from one of the below software-specific formats and then further annotate. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for the json data dictionary click here Validate with the vlmd command \u00b6 After finishing your work on the csv HEAL data dictionary, run the vlmd command to ensure it is HEAL-compliant with: vlmd --filepath data/heal-dd-output.json --inputtype jsontemplate Redcap: Data Dictionary CSV Export \u00b6 For users collecting data in a Redcap data management system, HEAL-compliant data dictionaries can be generated directly from Redcap exports. The redcap data dictionary export serves the purpose of providing variable level metadata in a standardized, tabular format and is generally easy to export. The HEAL data utilities leverages this user experience and standardized format to enable HEAL researchers to generate a Heal-compliant data dictionary. Export your Redcap data dictionary \u00b6 To download a Redcap CSV export do the following*: After logging in to your Redcap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific Redcap instance and version Run the vlmd command \u00b6 vlmd --filepath input/example_redcap_demo.redcap.csv --inputtype redcap.csv --outputdir output/heal-vlmd-from-redcap.csv SAS sas7bdat (and sas7bcat ) files \u00b6 To accommodate SAS users, HEAL data utilities supports the binary sas7bdat file format, which contains the actual data values (observations/records). This file also includes variable metadata (variable names and variable labels/ descriptions ). HEAL data utilities also provides the option to include a catalog file \u2013 sas7bcat format - with the sas7bdat . A sas7bcat file contains variable value labels, or encodings that can be mapped onto the corresponding data from a sas7bdat file. Creating a sas7bdat and a sas7bcat file \u00b6 Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template ( see here ). Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run; Run the vlmd command \u00b6 After creating the necessary sas7bdat and sas7bcat files, you can then run the vlmd command. Note, the sas7bcat files are optional. However, if you don't include a sas7bcat file, the encodings (i.e., value labels) will not be added. With the sas7bcat file: vlmd --filepath input/data.sas7bdat --sas7bcat-filepath input/formats.sas7bcat --inputtype sas7bdat Without the sas7bdat file: vlmd --filepath input/data.sas7bdat --inputtype sas7bdat SPSS .sav files \u00b6 For SPSS users, HEAL data utilities generates heal-compliant data dictionaries from SPSS's default file format for storing datasets: A SAV file. It not only stores the data itself but also stores metadata such as variable names, variable labels, types, and value labels. The HEAL data utilities extracts the data and metadata to create heal-compliant data dictionaries. Run the vlmd command \u00b6 vlmd --filepath data/example_pyreadstat_output.sav --inputtype sav Stata .dta files \u00b6 For Stata users, HEAL data utilities generates heal-compliant data dictionaries through Stata's default file format: the DTA files. DTA files not only store the data itself but also stores metadata such as variable names, variable labels, types, and value labels.","title":"Supported Input Formats"},{"location":"vlmd/supported_input_formats/#supported-input-formats","text":"In this section, supported formats for generating heal-compliant data dictionaries are listed. We also provide additional instructions on how to get the necessary input files format/software. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for either the csv data dictionary click here and for the json data dictionary click here","title":"Supported Input Formats"},{"location":"vlmd/supported_input_formats/#csv-datasets","text":"CSV (comma-separated values) is the main open tabular data format for storage and exchange. It is easy to create and understand using basic text editors in addition to popular spreadsheet software like Google Sheets and Excel. Importantly, it is simple and can be easily integrated into web applications and just about any software. Currently, the HEAL data utilities vlmd function can infer a minimal-HEAL compliant dataset by inferring name , type ,and enum (i.e., possible values). After this minimal data dictionary is generated, the researcher can further annotate it with fields' description and other optional properties in either the HEAL-compliant csv or json data dictionary (see the HEAL data dictionary template sections below for more information)","title":"csv Datasets"},{"location":"vlmd/supported_input_formats/#csv-heal-data-dictionary-eg-from-template","text":"HEAL data utilities can also input a csv HEAL data dictionary either from a manually filled out template or as an additional step after additional annotation (e.g., from the HEAL csv data dictionary output of the above file formats).","title":"csv HEAL data dictionary (e.g., from template)"},{"location":"vlmd/supported_input_formats/#creating-a-csv-heal-data-dictionary","text":"Use the template and start from scratch Click here to download a blank csv HEAL data dictionary template here Click here to download an example of filled out csv HEAL data dictionary template here Output from one of the below software-specific formats and then further annotate. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for either the csv data dictionary click here","title":"Creating a csv HEAL data dictionary"},{"location":"vlmd/supported_input_formats/#validate-with-the-vlmd-command","text":"After finishing your work on the csv HEAL data dictionary, run the vlmd command to ensure it is HEAL-compliant with: vlmd --filepath data/heal-dd-output.csv --inputtype csvtemplate","title":"Validate with the vlmd command"},{"location":"vlmd/supported_input_formats/#json-heal-data-dictionary-eg-from-template","text":"While the csv HEAL data dictionary provides a tabular format for HEAL-compliant data dictionaries, ultimately, these csv data dictionary files are converted to a json file (the most common format to store and exchange data within web applications such as the HEAL data platform). The HEAL data utilities vlmd tool can also input this json HEAL data dictionary either from a manually filled out template or as an additional step after additional annotation. Another advantage of json HEAL data dictionaries is that one can specify metadata describing the data dictionary as a whole (e.g., the description and title ).","title":"json HEAL data dictionary (e.g., from template)"},{"location":"vlmd/supported_input_formats/#creating-a-json-heal-data-dictionary","text":"Use the template and start from scratch (click on the template below to expand) Click here to download a blank json HEAL data dictionary template here Click here to download an example of filled out json HEAL data dictionary template here Output from one of the below software-specific formats and then further annotate. Note To further annotate your outputted data dictionaries, see the variable level metadata field properties (with examples) for the json data dictionary click here","title":"Creating a json HEAL data dictionary"},{"location":"vlmd/supported_input_formats/#validate-with-the-vlmd-command_1","text":"After finishing your work on the csv HEAL data dictionary, run the vlmd command to ensure it is HEAL-compliant with: vlmd --filepath data/heal-dd-output.json --inputtype jsontemplate","title":"Validate with the vlmd command"},{"location":"vlmd/supported_input_formats/#redcap-data-dictionary-csv-export","text":"For users collecting data in a Redcap data management system, HEAL-compliant data dictionaries can be generated directly from Redcap exports. The redcap data dictionary export serves the purpose of providing variable level metadata in a standardized, tabular format and is generally easy to export. The HEAL data utilities leverages this user experience and standardized format to enable HEAL researchers to generate a Heal-compliant data dictionary.","title":"Redcap: Data Dictionary CSV Export"},{"location":"vlmd/supported_input_formats/#export-your-redcap-data-dictionary","text":"To download a Redcap CSV export do the following*: After logging in to your Redcap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific Redcap instance and version","title":"Export your Redcap data dictionary"},{"location":"vlmd/supported_input_formats/#run-the-vlmd-command","text":"vlmd --filepath input/example_redcap_demo.redcap.csv --inputtype redcap.csv --outputdir output/heal-vlmd-from-redcap.csv","title":"Run the vlmd command"},{"location":"vlmd/supported_input_formats/#sas-sas7bdat-and-sas7bcat-files","text":"To accommodate SAS users, HEAL data utilities supports the binary sas7bdat file format, which contains the actual data values (observations/records). This file also includes variable metadata (variable names and variable labels/ descriptions ). HEAL data utilities also provides the option to include a catalog file \u2013 sas7bcat format - with the sas7bdat . A sas7bcat file contains variable value labels, or encodings that can be mapped onto the corresponding data from a sas7bdat file.","title":"SAS sas7bdat (and sas7bcat) files"},{"location":"vlmd/supported_input_formats/#creating-a-sas7bdat-and-a-sas7bcat-file","text":"Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template ( see here ). Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run;","title":"Creating a sas7bdat and a sas7bcat file"},{"location":"vlmd/supported_input_formats/#run-the-vlmd-command_1","text":"After creating the necessary sas7bdat and sas7bcat files, you can then run the vlmd command. Note, the sas7bcat files are optional. However, if you don't include a sas7bcat file, the encodings (i.e., value labels) will not be added. With the sas7bcat file: vlmd --filepath input/data.sas7bdat --sas7bcat-filepath input/formats.sas7bcat --inputtype sas7bdat Without the sas7bdat file: vlmd --filepath input/data.sas7bdat --inputtype sas7bdat","title":"Run the vlmd command"},{"location":"vlmd/supported_input_formats/#spss-sav-files","text":"For SPSS users, HEAL data utilities generates heal-compliant data dictionaries from SPSS's default file format for storing datasets: A SAV file. It not only stores the data itself but also stores metadata such as variable names, variable labels, types, and value labels. The HEAL data utilities extracts the data and metadata to create heal-compliant data dictionaries.","title":"SPSS .sav files"},{"location":"vlmd/supported_input_formats/#run-the-vlmd-command_2","text":"vlmd --filepath data/example_pyreadstat_output.sav --inputtype sav","title":"Run the vlmd command"},{"location":"vlmd/supported_input_formats/#stata-dta-files","text":"For Stata users, HEAL data utilities generates heal-compliant data dictionaries through Stata's default file format: the DTA files. DTA files not only store the data itself but also stores metadata such as variable names, variable labels, types, and value labels.","title":"Stata .dta files"},{"location":"vlmd/rendered-schemas/","text":"HEAL data dictionary field properties \u00b6 Click on each property to view information about that property (such as a description, examples, etc) Note enum type means that a field can only be one of a certain set of possible values.","title":"HEAL data dictionary field properties"},{"location":"vlmd/rendered-schemas/#heal-data-dictionary-field-properties","text":"Click on each property to view information about that property (such as a description, examples, etc) Note enum type means that a field can only be one of a certain set of possible values.","title":"HEAL data dictionary field properties"},{"location":"vlmd/rendered-schemas/csv-fields/","text":"HEAL Variable Level Metadata Fields HEAL Variable Level Metadata Fields Type: object Variable level metadata individual fields integrated into the variable level metadata object within the HEAL platform metadata service. Note, only name and description are required. Listed at the end of the description are suggested \"priority\" levels in brackets (e.g., [ ]): 1. [Required]: Needs to be filled out to be valid. 2. [Highly recommended]: Greatly help using the data dictionary but not required. 3. [Optional, if applicable]: May only be applicable to certain fields. 4. [Autopopulated, if not filled]: These fields are intended to be autopopulated from other fields but can be filled out if desired. 5. [Experimental]: These fields are not currently used but are in development. module root module Type: string The section, form, survey instrument, set of measures or other broad category used to group variables. Examples: \"Demographics\" \"PROMIS\" \"Substance use\" \"Medical History\" \"Sleep questions\" \"Physical activity\" name Required root name Type: string The name of a variable (i.e., field) as it appears in the data. [Required] title root title Type: string The human-readable title or label of the variable. [Highly recommended] Example: \"My Variable (for name of my_variable)\" description Required root description Type: string An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). [Required] Examples: \"Definition\" \"Question text (if a survey)\" type root type Type: enum (of string) A classification or category of a particular data element or property expected or allowed in the dataset. number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278])) Must be one of: \"number\" \"integer\" \"string\" \"any\" \"boolean\" \"date\" \"datetime\" \"time\" \"year\" \"yearmonth\" \"duration\" \"geopoint\" format root format A format taken from one of the frictionless specification schemas. For example, for tabular data, there is the Table Schema specification Each format is dependent on the type specified. For example: If type is \"string\", then see the String formats. If type is one of the date-like formats, then see Date formats. Any of String Format Date Format Geopoint Format geojson root format anyOf String Format Type: enum (of string) Must be one of: \"uri\" \"email\" \"binary\" \"uuid\" root format anyOf Date Format Type: object A format for a date variable ( date , time , datetime ). \\n\\t* default : An ISO8601 format string. \\n\\t* any : Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies. \\n\\t* {PATTERN} : The value can be parsed according to {PATTERN} , which MUST follow the date formatting syntax of C / Python strftime . \\nExamples: %Y-%m-%d (for date, e.g., 2023-05-25) %Y%-%d (for date, e.g., 20230525) for date without dashes\" %Y-%m-%dT%H:%M:%S (for datetime, e.g., 2023-05-25T10:30:45) %Y-%m-%dT%H:%M:%SZ (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z) %Y-%m-%dT%H:%M:%S%z (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300) %Y-%m-%dT%H:%M (for datetime without seconds, e.g., 2023-05-25T10:30) %Y-%m-%dT%H (for datetime without minutes and seconds, e.g., 2023-05-25T10) %H:%M:%S (for time, e.g., 10:30:45) %H:%M:%SZ (for time with UTC timezone, e.g., 10:30:45Z) %H:%M:%S%z (for time with timezone offset, e.g., 10:30:45+0300) root format anyOf Geopoint Format The two types of formats for geopoint (describing a geographic point). One of Option 1 Option 2 root format anyOf Geopoint Format oneOf item 0 Type: array A JSON array or a string parsable as a JSON array where each item is a number with the first as the latitude and the second as longitude. root format anyOf Geopoint Format oneOf item 1 Type: object Contains latitude and longitude with two keys (\"lat\" and \"long\") with number items mapped to each key. root format anyOf geojson Type: enum (of string) The JSON object according to the geojson spec. Must be one of: \"topojson\" \"default\" constraints.maxLength root constraints.maxLength Type: integer Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. [Optional,if applicable] constraints.enum root constraints.enum Type: string Constrains possible values to a set of values. [Optional,if applicable] Must match regular expression: ^(?:[^|]+\\||[^|]*)(?:[^|]*\\|)*[^|]*$ constraints.pattern root constraints.pattern Type: string A regular expression pattern the data MUST conform to. [Optional,if applicable] constraints.maximum root constraints.maximum Type: integer Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different then maxLength property. [Optional,if applicable] encodings root encodings Type: string Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values. Additionally, as another use case, this field provides a way to store categoricals that are stored as \"short\" labels (such as abbreviations). [Optional,if applicable] Must match regular expression: ^(?:.*?=.*?(?:\\||$))+$ Examples: \"0=No|1=Yes\" \"HW=Hello world|GBW=Good bye world|HM=Hi,Mike\" ordered root ordered Type: boolean Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). [Optional,if applicable] missingValues root missingValues Type: string A list of missing values specific to a variable. [Optional, if applicable] Must match regular expression: ^(?:[^|]+\\||[^|]*)(?:[^|]*\\|)*[^|]*$ trueValues root trueValues Type: string For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. [Optional, if applicable] Must match regular expression: ^(?:[^|]+\\||[^|]*)(?:[^|]*\\|)*[^|]*$ Examples: \"Required|REQUIRED\" \"required|Yes|Y|Checked\" \"Checked\" \"Required\" falseValues root falseValues Type: string For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. Must match regular expression: ^(?:[^|]+\\||[^|]*)(?:[^|]*\\|)*[^|]*$ repo_link root repo_link Type: string A link to the variable as it exists on the home repository, if applicable cde_id.source root cde_id.source Type: string cde_id.id root cde_id.id Type: string ontology_id.relation root ontology_id.relation Type: string ontology_id.source root ontology_id.source Type: string ontology_id.id root ontology_id.id Type: string standardsMappings.type root standardsMappings.type Type: string The type of mapping linked to a published set of standard variables such as the NIH Common Data Elements program. [Autopopulated, if not filled] Examples: \"cde\" \"ontology\" \"reference_list\" standardsMappings.label root standardsMappings.label Type: string A free text label of a mapping indicating a mapping(s) to a published set of standard variables such as the NIH Common Data Elements program. [Autopopulated, if not filled] Examples: \"substance use\" \"chemical compound\" \"promis\" standardsMappings.url root standardsMappings.url Type: string Format: uri The url that links out to the published, standardized mapping. [Autopopulated, if not filled] Example: \"https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\" standardsMappings.source root standardsMappings.source Type: string The source of the standardized variable. Example: \"TBD (will have controlled vocabulary)\" standardsMappings.id root standardsMappings.id Type: string The id locating the individual mapping within the given source. relatedConcepts.type root relatedConcepts.type Type: string The type of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) [Autopopulated, if not filled] relatedConcepts.label root relatedConcepts.label Type: string A free text label of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) [Autopopulated, if not filled] relatedConcepts.url root relatedConcepts.url Type: string Format: uri The url that links out to the published, standardized concept. [Autopopulated, if not filled] Example: \"https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\" relatedConcepts.source root relatedConcepts.source Type: string The source of the related concept. [Autopopulated, if not filled] Example: \"TBD (will have controlled vocabulary)\" relatedConcepts.id root relatedConcepts.id Type: string The id locating the individual mapping within the given source. [Autopopulated, if not filled] univarStats.median root univarStats.median Type: number univarStats.mean root univarStats.mean Type: number univarStats.std root univarStats.std Type: number univarStats.min root univarStats.min Type: number univarStats.max root univarStats.max Type: number univarStats.mode root univarStats.mode Type: number univarStats.count root univarStats.count Type: integer Value must be greater or equal to 0 univarStats.twentyFifthPercentile root univarStats.twentyFifthPercentile Type: number univarStats.seventyFifthPercentile root univarStats.seventyFifthPercentile Type: number univarStats.categoricalMarginals.name root univarStats.categoricalMarginals.name Type: string univarStats.categoricalMarginals.count root univarStats.categoricalMarginals.count Type: integer Additional Properties Additional Properties of any type are allowed. root additionalProperties Type: object Generated using json-schema-for-humans on 2023-06-15 at 10:23:11 -0500","title":"CSV Data dictionary"},{"location":"vlmd/rendered-schemas/json-fields/","text":"HEAL Variable Level Metadata Fields HEAL Variable Level Metadata Fields Type: object Variable level metadata individual fields integrated into the variable level metadata object within the HEAL platform metadata service. Note, only name and description are required. Listed at the end of the description are suggested \"priority\" levels in brackets (e.g., [ ]): 1. [Required]: Needs to be filled out to be valid. 2. [Highly recommended]: Greatly help using the data dictionary but not required. 3. [Optional, if applicable]: May only be applicable to certain fields. 4. [Autopopulated, if not filled]: These fields are intended to be autopopulated from other fields but can be filled out if desired. 5. [Experimental]: These fields are not currently used but are in development. module root module Type: string The section, form, survey instrument, set of measures or other broad category used to group variables. Examples: \"Demographics\" \"PROMIS\" \"Substance use\" \"Medical History\" \"Sleep questions\" \"Physical activity\" name Required root name Type: string The name of a variable (i.e., field) as it appears in the data. [Required] title root title Type: string The human-readable title or label of the variable. [Highly recommended] Example: \"My Variable (for name of my_variable)\" description Required root description Type: string An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). [Required] Examples: \"Definition\" \"Question text (if a survey)\" type root type Type: enum (of string) A classification or category of a particular data element or property expected or allowed in the dataset. number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278])) Must be one of: \"number\" \"integer\" \"string\" \"any\" \"boolean\" \"date\" \"datetime\" \"time\" \"year\" \"yearmonth\" \"duration\" \"geopoint\" format root format A format taken from one of the frictionless specification schemas. For example, for tabular data, there is the Table Schema specification Each format is dependent on the type specified. For example: If type is \"string\", then see the String formats. If type is one of the date-like formats, then see Date formats. Any of String Format Date Format Geopoint Format geojson root format anyOf String Format Type: enum (of string) Must be one of: \"uri\" \"email\" \"binary\" \"uuid\" root format anyOf Date Format Type: object A format for a date variable ( date , time , datetime ). \\n\\t* default : An ISO8601 format string. \\n\\t* any : Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies. \\n\\t* {PATTERN} : The value can be parsed according to {PATTERN} , which MUST follow the date formatting syntax of C / Python strftime . \\nExamples: %Y-%m-%d (for date, e.g., 2023-05-25) %Y%-%d (for date, e.g., 20230525) for date without dashes\" %Y-%m-%dT%H:%M:%S (for datetime, e.g., 2023-05-25T10:30:45) %Y-%m-%dT%H:%M:%SZ (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z) %Y-%m-%dT%H:%M:%S%z (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300) %Y-%m-%dT%H:%M (for datetime without seconds, e.g., 2023-05-25T10:30) %Y-%m-%dT%H (for datetime without minutes and seconds, e.g., 2023-05-25T10) %H:%M:%S (for time, e.g., 10:30:45) %H:%M:%SZ (for time with UTC timezone, e.g., 10:30:45Z) %H:%M:%S%z (for time with timezone offset, e.g., 10:30:45+0300) root format anyOf Geopoint Format The two types of formats for geopoint (describing a geographic point). One of Option 1 Option 2 root format anyOf Geopoint Format oneOf item 0 Type: array A JSON array or a string parsable as a JSON array where each item is a number with the first as the latitude and the second as longitude. root format anyOf Geopoint Format oneOf item 1 Type: object Contains latitude and longitude with two keys (\"lat\" and \"long\") with number items mapped to each key. root format anyOf geojson Type: enum (of string) The JSON object according to the geojson spec. Must be one of: \"topojson\" \"default\" constraints root constraints Type: object maxLength root constraints maxLength Type: integer Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. [Optional,if applicable] enum root constraints enum Type: array Constrains possible values to a set of values. [Optional,if applicable] pattern root constraints pattern Type: string A regular expression pattern the data MUST conform to. [Optional,if applicable] maximum root constraints maximum Type: integer Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different then maxLength property. [Optional,if applicable] encodings root encodings Type: object Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values. Additionally, as another use case, this field provides a way to store categoricals that are stored as \"short\" labels (such as abbreviations). [Optional,if applicable] Examples: { \"0\" : \"No\" , \"1\" : \"Yes\" } { \"HW\" : \"Hello world\" , \"GBW\" : \"Good bye world\" , \"HM\" : \"Hi, Mike\" } ordered root ordered Type: boolean Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). [Optional,if applicable] missingValues root missingValues Type: array A list of missing values specific to a variable. [Highly recommended] trueValues root trueValues Type: array of string For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. [Optional, if applicable] Each item of this array must be: root trueValues trueValues items Type: string Examples: \"Required\" \"REQUIRED\" \"required\" \"Yes\" \"Checked\\\"\" falseValues root falseValues Type: array For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. repo_link root repo_link Type: string A link to the variable as it exists on the home repository, if applicable cde_id root cde_id Type: array of object [FUTURE WARNING: WILL BE DEPRECATED] Use standardsMapping . The source and id for the NIH Common Data Elements program. Each item of this array must be: root cde_id cde_id items Type: object source root cde_id cde_id items source Type: string id root cde_id cde_id items id Type: string ontology_id root ontology_id Type: array of object [FUTURE WARNING: WILL BE DEPRECATED] - Use relatedConcepts . Ontological information for the given variable as indicated by the source, id, and relation to the specified classification. One or more ontology classifications can be specified. Each item of this array must be: root ontology_id ontology_id items Type: object relation root ontology_id ontology_id items relation Type: string source root ontology_id ontology_id items source Type: string id root ontology_id ontology_id items id Type: string standardsMappings root standardsMappings Type: array of object A published set of standard variables such as the NIH Common Data Elements program. [Autopopulated, if not filled] Each item of this array must be: root standardsMappings standardsMappings items Type: object type root standardsMappings standardsMappings items type Type: string The type of mapping linked to a published set of standard variables such as the NIH Common Data Elements program. [Autopopulated, if not filled] Examples: \"cde\" \"ontology\" \"reference_list\" label root standardsMappings standardsMappings items label Type: string A free text label of a mapping indicating a mapping(s) to a published set of standard variables such as the NIH Common Data Elements program. [Autopopulated, if not filled] Examples: \"substance use\" \"chemical compound\" \"promis\" url root standardsMappings standardsMappings items url Type: string Format: uri The url that links out to the published, standardized mapping. [Autopopulated, if not filled] Example: \"https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\" source root standardsMappings standardsMappings items source Type: string The source of the standardized variable. Example: \"TBD (will have controlled vocabulary)\" id root standardsMappings standardsMappings items id Type: string The id locating the individual mapping within the given source. relatedConcepts root relatedConcepts Type: array of object Mappings to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) [Autopopulated, if not filled] Each item of this array must be: root relatedConcepts relatedConcepts items Type: object type root relatedConcepts relatedConcepts items type Type: string The type of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) [Autopopulated, if not filled] label root relatedConcepts relatedConcepts items label Type: string A free text label of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) [Autopopulated, if not filled] url root relatedConcepts relatedConcepts items url Type: string Format: uri The url that links out to the published, standardized concept. [Autopopulated, if not filled] Example: \"https://cde.nlm.nih.gov/deView?tinyId=XyuSGdTTI\" source root relatedConcepts relatedConcepts items source Type: string The source of the related concept. [Autopopulated, if not filled] Example: \"TBD (will have controlled vocabulary)\" id root relatedConcepts relatedConcepts items id Type: string The id locating the individual mapping within the given source. [Autopopulated, if not filled] univarStats root univarStats Type: object Univariate statistics inferred from the data about the given variable [Experimental] median root univarStats median Type: number mean root univarStats mean Type: number std root univarStats std Type: number min root univarStats min Type: number max root univarStats max Type: number mode root univarStats mode Type: number count root univarStats count Type: integer Value must be greater or equal to 0 twentyFifthPercentile root univarStats twentyFifthPercentile Type: number seventyFifthPercentile root univarStats seventyFifthPercentile Type: number categoricalMarginals root univarStats categoricalMarginals Type: array of object Each item of this array must be: root univarStats categoricalMarginals categoricalMarginals items Type: object name root univarStats categoricalMarginals categoricalMarginals items name Type: string count root univarStats categoricalMarginals categoricalMarginals items count Type: integer Additional Properties Additional Properties of any type are allowed. root additionalProperties Type: object Generated using json-schema-for-humans on 2023-06-15 at 10:23:11 -0500","title":"JSON Data dictionary"}]}